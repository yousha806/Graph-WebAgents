{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-md-00",
   "metadata": {},
   "source": [
    "# Mind2Web â€” Qwen3-VL Baselines\n",
    "## Baselines:\n",
    "- **axtree_multimodal** â€” image + text + AXTree\n",
    "- **axtree_multimodal_cot** â€” image + text + AXTree + Chain-of-Thought\n",
    "\n",
    "### Key fix vs previous notebook\n",
    "- `max_new_tokens` is **separate** per baseline: `32` for direct, `512` for CoT.\n",
    "  - CoT was producing 0 accuracy because 32 tokens was never enough to finish reasoning AND write the final action line.\n",
    "- Dry-run sanity check on 3 samples before full loop so bugs are caught early.\n",
    "- Metrics use `vlm_inference_script.py` compatible format + your `compute_metrics` logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-01",
   "metadata": {},
   "source": [
    "## Cell 1 â€” Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "Hit:1 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble InRelease\n",
      "Hit:2 https://download.docker.com/linux/ubuntu noble InRelease\n",
      "Get:3 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]\n",
      "Get:4 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu noble-security InRelease [126 kB]\n",
      "Get:6 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease [1477 B]\n",
      "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64  InRelease\n",
      "Hit:8 https://fsx-lustre-client-repo.s3.amazonaws.com/ubuntu noble InRelease\n",
      "Hit:9 https://apt.corretto.aws stable InRelease\n",
      "Get:10 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates/main amd64 Components [175 kB]\n",
      "Get:11 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates/universe amd64 Components [385 kB]\n",
      "Get:12 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Components [212 B]\n",
      "Get:13 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Components [940 B]\n",
      "Get:14 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-backports/main amd64 Components [7312 B]\n",
      "Get:15 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-backports/universe amd64 Components [10.5 kB]\n",
      "Get:16 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-backports/restricted amd64 Components [212 B]\n",
      "Get:17 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-backports/multiverse amd64 Components [212 B]\n",
      "Get:18 http://security.ubuntu.com/ubuntu noble-security/main amd64 Components [21.5 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Components [74.2 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Components [212 B]\n",
      "Get:21 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 Components [212 B]\n",
      "Fetched 1055 kB in 1s (1784 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "libasound2t64 is already the newest version (1.2.11-1ubuntu0.2).\n",
      "libatk-bridge2.0-0t64 is already the newest version (2.52.0-1build1).\n",
      "libatk1.0-0t64 is already the newest version (2.52.0-1build1).\n",
      "libatspi2.0-0t64 is already the newest version (2.52.0-1build1).\n",
      "libcairo2 is already the newest version (1.18.0-3build1).\n",
      "libcups2t64 is already the newest version (2.4.7-1.2ubuntu7.9).\n",
      "libdbus-1-3 is already the newest version (1.14.10-4ubuntu4.1).\n",
      "libdrm2 is already the newest version (2.4.125-1ubuntu0.1~24.04.1).\n",
      "libgbm1 is already the newest version (25.2.8-0ubuntu0.24.04.1).\n",
      "libglib2.0-0t64 is already the newest version (2.80.0-6ubuntu3.8).\n",
      "libnspr4 is already the newest version (2:4.35-1.1build1).\n",
      "libnss3 is already the newest version (2:3.98-1build1).\n",
      "libpango-1.0-0 is already the newest version (1.52.1+ds-1build1).\n",
      "libx11-6 is already the newest version (2:1.8.7-1build1).\n",
      "libxcb1 is already the newest version (1.15-1ubuntu2).\n",
      "libxcomposite1 is already the newest version (1:0.4.5-1build3).\n",
      "libxdamage1 is already the newest version (1:1.1.6-1build1).\n",
      "libxext6 is already the newest version (2:1.3.4-1build2).\n",
      "libxfixes3 is already the newest version (1:6.0.0-2build1).\n",
      "libxkbcommon0 is already the newest version (1.6.0-1build1).\n",
      "libxrandr2 is already the newest version (2:1.5.2-2build1).\n",
      "xvfb is already the newest version (2:21.1.12-1ubuntu1.5).\n",
      "fonts-noto-color-emoji is already the newest version (2.047-0ubuntu0.24.04.1).\n",
      "fonts-unifont is already the newest version (1:15.1.01-1build1).\n",
      "libfontconfig1 is already the newest version (2.15.0-1.1ubuntu2).\n",
      "libfreetype6 is already the newest version (2.13.2+dfsg-1build3).\n",
      "xfonts-cyrillic is already the newest version (1:1.0.5+nmu1).\n",
      "xfonts-scalable is already the newest version (1:1.0.3-1.3).\n",
      "fonts-liberation is already the newest version (1:2.1.5-3).\n",
      "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
      "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
      "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
      "fonts-freefont-ttf is already the newest version (20211204+svn4273-2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "All dependencies ready.\n"
     ]
    }
   ],
   "source": [
    "import subprocess, sys\n",
    "pkgs = [\n",
    "    'git+https://github.com/huggingface/transformers.git',\n",
    "    'accelerate',\n",
    "    'qwen-vl-utils',\n",
    "    'datasets',\n",
    "    'playwright==1.46.0',\n",
    "    'tqdm',\n",
    "    'Pillow',\n",
    "    'matplotlib',\n",
    "    'scikit-learn',\n",
    "    'bitsandbytes',\n",
    "]\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q'] + pkgs, check=True)\n",
    "subprocess.run([sys.executable, '-m', 'playwright', 'install', 'chromium'], check=True)\n",
    "subprocess.run(['sudo', sys.executable, '-m', 'playwright', 'install-deps', 'chromium'], check=True)\n",
    "print('All dependencies ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-02",
   "metadata": {},
   "source": [
    "## Cell 2 â€” Imports & GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pytorch/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch : 2.9.1+cu130\n",
      "CUDA    : True\n",
      "GPU     : NVIDIA A10G\n",
      "VRAM    : 23.7 GB\n"
     ]
    }
   ],
   "source": [
    "import json, re, gc, time\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "print(f'PyTorch : {torch.__version__}')\n",
    "print(f'CUDA    : {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU     : {torch.cuda.get_device_name(0)}')\n",
    "    print(f'VRAM    : {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-03",
   "metadata": {},
   "source": [
    "## Cell 3 â€” Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_name\": \"Qwen/Qwen3-VL-8B-Instruct\",\n",
      "  \"max_new_tokens_direct\": \"32\",\n",
      "  \"max_new_tokens_cot\": \"512\",\n",
      "  \"torch_dtype\": \"torch.bfloat16\",\n",
      "  \"splits\": \"['test_task', 'test_website', 'test_domain']\",\n",
      "  \"data_dir\": \"data/mind2web\",\n",
      "  \"axtree_dir\": \"data/mind2web_axtree\",\n",
      "  \"max_samples\": \"None\",\n",
      "  \"output_dir\": \"results\",\n",
      "  \"max_image_size\": \"512\",\n",
      "  \"max_axtree_chars\": \"1500\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "CFG = dict(\n",
    "    model_name        = 'Qwen/Qwen3-VL-8B-Instruct',\n",
    "    # âš ï¸  KEY FIX: separate token budgets per baseline\n",
    "    max_new_tokens_direct = 32,    # direct action: never more than ~10 tokens\n",
    "    max_new_tokens_cot    = 512,   # CoT: needs room to reason THEN write the action\n",
    "    torch_dtype       = torch.bfloat16,\n",
    "    splits            = ['test_task', 'test_website', 'test_domain'],\n",
    "    data_dir          = 'data/mind2web',\n",
    "    axtree_dir        = 'data/mind2web_axtree',\n",
    "    max_samples       = None,      # set to e.g. 50 for a quick smoke-test run\n",
    "    output_dir        = 'results',\n",
    "    max_image_size    = 512,\n",
    "    max_axtree_chars  = 1500,\n",
    ")\n",
    "for d in [CFG['data_dir'], CFG['axtree_dir'], CFG['output_dir']]:\n",
    "    Path(d).mkdir(parents=True, exist_ok=True)\n",
    "print(json.dumps({k: str(v) for k, v in CFG.items()}, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-04",
   "metadata": {},
   "source": [
    "## Cell 4 â€” Download Mind2Web dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test_task: already on disk, skipping.\n",
      "  test_website: already on disk, skipping.\n",
      "  test_domain: already on disk, skipping.\n",
      "Download done.\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'osunlp/Multimodal-Mind2Web'\n",
    "for split in CFG['splits']:\n",
    "    split_path = Path(CFG['data_dir']) / split\n",
    "    if split_path.exists():\n",
    "        print(f'  {split}: already on disk, skipping.')\n",
    "        continue\n",
    "    print(f'  Downloading {split} ...')\n",
    "    ds = load_dataset(DATASET_NAME, split=split)\n",
    "    ds.save_to_disk(str(split_path))\n",
    "    print(f'  {split}: {len(ds)} records -> {split_path}')\n",
    "print('Download done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-05",
   "metadata": {},
   "source": [
    "## Cell 5 â€” AXTree precomputation (Playwright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test_task: already computed, skipping.\n",
      "  test_website: already computed, skipping.\n",
      "  test_domain: already computed, skipping.\n",
      "AXTree precomputation done.\n"
     ]
    }
   ],
   "source": [
    "import re as _re, json as _json\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "def flatten_axtree(snapshot, max_nodes=3000, max_chars=40000):\n",
    "    if not snapshot:\n",
    "        return ''\n",
    "    lines = []\n",
    "    stack = [(snapshot, 0)]\n",
    "    while stack and len(lines) < max_nodes:\n",
    "        node, depth = stack.pop()\n",
    "        role  = node.get('role', '')\n",
    "        name  = (node.get('name') or '').strip()\n",
    "        value = node.get('value')\n",
    "        vstr  = '' if value is None else f' value={str(value).strip()}'\n",
    "        lines.append('  ' * depth + f'{role}: {name}{vstr}'.strip())\n",
    "        for c in reversed(node.get('children') or []):\n",
    "            stack.append((c, depth + 1))\n",
    "        if sum(len(x) + 1 for x in lines) > max_chars:\n",
    "            break\n",
    "    return '\\n'.join(lines)[:max_chars]\n",
    "\n",
    "async def compute_axtrees_for_split(split):\n",
    "    out_path = Path(CFG['axtree_dir']) / split\n",
    "    if out_path.exists():\n",
    "        print(f'  {split}: already computed, skipping.')\n",
    "        return\n",
    "    ds = load_from_disk(str(Path(CFG['data_dir']) / split))\n",
    "    print(f'  {split}: {len(ds)} examples ...')\n",
    "    axtree_json_col, axtree_text_col = [], []\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context(java_script_enabled=False)\n",
    "        page = await context.new_page()\n",
    "        try:\n",
    "            for ex in tqdm(ds, desc=split):\n",
    "                await page.set_content(ex.get('cleaned_html', ''), wait_until='domcontentloaded')\n",
    "                snap = await page.accessibility.snapshot(interesting_only=False)\n",
    "                snap = snap or {}\n",
    "                axtree_json_col.append(_json.dumps(snap, ensure_ascii=False))\n",
    "                axtree_text_col.append(flatten_axtree(snap))\n",
    "        finally:\n",
    "            await context.close()\n",
    "            await browser.close()\n",
    "    ds = ds.add_column('axtree_json', axtree_json_col)\n",
    "    ds = ds.add_column('axtree_text', axtree_text_col)\n",
    "    ds.save_to_disk(str(out_path))\n",
    "    print(f'  Saved -> {out_path}')\n",
    "\n",
    "for split in CFG['splits']:\n",
    "    await compute_axtrees_for_split(split)\n",
    "print('AXTree precomputation done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-06",
   "metadata": {},
   "source": [
    "## Cell 6 â€” Load datasets into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test_task: 1339 samples | columns: ['action_uid', 'raw_html', 'cleaned_html', 'operation', 'pos_candidates', 'neg_candidates', 'website', 'domain', 'subdomain', 'annotation_id', 'confirmed_task', 'screenshot', 'action_reprs', 'target_action_index', 'target_action_reprs', 'axtree_json', 'axtree_text']\n",
      "  test_website: 1019 samples | columns: ['action_uid', 'raw_html', 'cleaned_html', 'operation', 'pos_candidates', 'neg_candidates', 'website', 'domain', 'subdomain', 'annotation_id', 'confirmed_task', 'screenshot', 'action_reprs', 'target_action_index', 'target_action_reprs', 'axtree_json', 'axtree_text']\n",
      "  test_domain: 4060 samples | columns: ['action_uid', 'raw_html', 'cleaned_html', 'operation', 'pos_candidates', 'neg_candidates', 'website', 'domain', 'subdomain', 'annotation_id', 'confirmed_task', 'screenshot', 'action_reprs', 'target_action_index', 'target_action_reprs', 'axtree_json', 'axtree_text']\n"
     ]
    }
   ],
   "source": [
    "datasets_dict = {}\n",
    "for split in CFG['splits']:\n",
    "    ds = load_from_disk(str(Path(CFG['axtree_dir']) / split))\n",
    "    if CFG['max_samples']:\n",
    "        ds = ds.select(range(CFG['max_samples']))\n",
    "    datasets_dict[split] = ds\n",
    "    print(f'  {split}: {len(ds)} samples | columns: {ds.column_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-07",
   "metadata": {},
   "source": [
    "## Cell 7 â€” Load model (4-bit quantized)\n",
    "Using 4-bit NF4 to fit in GPU VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen3-VL-8B-Instruct in 4-bit ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2019b2f119c4af2b42cce41a7071aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f3d658c01445379af01fb7a67a5769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae10867f78b4b72a07bb924e69d71ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready.\n",
      "VRAM used: 6.40 GB\n"
     ]
    }
   ],
   "source": [
    "print(f'Loading {CFG[\"model_name\"]} in 4-bit ...')\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    CFG['model_name'],\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    ")\n",
    "model.eval()\n",
    "processor = AutoProcessor.from_pretrained(CFG['model_name'])\n",
    "print('Model ready.')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'VRAM used: {torch.cuda.memory_allocated()/1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-08",
   "metadata": {},
   "source": [
    "## Cell 8 â€” Prompts, inference helpers, parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All helpers defined.\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# System prompts\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SYSTEM_PROMPT_DIRECT = (\n",
    "    'You are a web automation agent.\\n'\n",
    "    'Given a task, a screenshot, and the page accessibility tree (AXTree), '\n",
    "    'predict the single best next action.\\n\\n'\n",
    "    'Valid formats (must match exactly):\\n'\n",
    "    'CLICK <element_label>\\n'\n",
    "    'TYPE <element_label> <text>\\n'\n",
    "    'SELECT <element_label> <option>\\n'\n",
    "    'SCROLL up\\n'\n",
    "    'SCROLL down\\n'\n",
    "    'PRESS <key>\\n'\n",
    "    'STOP <answer>\\n\\n'\n",
    "    'IMPORTANT: Output ONLY the action line. No explanation, no preamble.'\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT_COT = (\n",
    "    'You are a web automation agent.\\n'\n",
    "    'Given a task, a screenshot, and the page accessibility tree (AXTree), '\n",
    "    'predict the single best next action.\\n\\n'\n",
    "    'Valid action formats:\\n'\n",
    "    'CLICK <element_label>\\n'\n",
    "    'TYPE <element_label> <text>\\n'\n",
    "    'SELECT <element_label> <option>\\n'\n",
    "    'SCROLL up\\n'\n",
    "    'SCROLL down\\n'\n",
    "    'PRESS <key>\\n'\n",
    "    'STOP <answer>\\n\\n'\n",
    "    'IMPORTANT: Think step-by-step first. '\n",
    "    'Your FINAL line must be exactly one action from the list above and nothing else.'\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Image helper\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def ensure_image(obj):\n",
    "    if isinstance(obj, Image.Image):\n",
    "        img = obj\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        img = Image.fromarray(obj)\n",
    "    elif isinstance(obj, str):\n",
    "        img = Image.open(obj).convert('RGB')\n",
    "    else:\n",
    "        raise TypeError(f'Cannot convert {type(obj)} to image')\n",
    "    img = img.convert('RGB')\n",
    "    w, h = img.size\n",
    "    if max(w, h) > CFG['max_image_size']:\n",
    "        scale = CFG['max_image_size'] / max(w, h)\n",
    "        img = img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
    "    return img\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Message builders\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_messages_axtree(row):\n",
    "    \"\"\"Baseline A: multimodal + AXTree, direct answer.\"\"\"\n",
    "    img    = ensure_image(row['screenshot'])\n",
    "    axtree = row['axtree_text'][:CFG['max_axtree_chars']]\n",
    "    return [{\n",
    "        'role': 'user',\n",
    "        'content': [\n",
    "            {'type': 'image', 'image': img},\n",
    "            {'type': 'text', 'text': (\n",
    "                f\"{SYSTEM_PROMPT_DIRECT}\\n\\n\"\n",
    "                f\"Task: {row['confirmed_task']}\\n\\n\"\n",
    "                f\"AXTree:\\n{axtree}\\n\\n\"\n",
    "                'What is the next action?'\n",
    "            )},\n",
    "        ],\n",
    "    }]\n",
    "\n",
    "def build_messages_axtree_cot(row):\n",
    "    \"\"\"Baseline B: multimodal + AXTree + Chain-of-Thought.\"\"\"\n",
    "    img    = ensure_image(row['screenshot'])\n",
    "    axtree = row['axtree_text'][:CFG['max_axtree_chars']]\n",
    "    return [{\n",
    "        'role': 'user',\n",
    "        'content': [\n",
    "            {'type': 'image', 'image': img},\n",
    "            {'type': 'text', 'text': (\n",
    "                f\"{SYSTEM_PROMPT_COT}\\n\\n\"\n",
    "                f\"Task: {row['confirmed_task']}\\n\\n\"\n",
    "                f\"AXTree:\\n{axtree}\\n\\n\"\n",
    "                'Think through each step, then write your final action on the last line.'\n",
    "            )},\n",
    "        ],\n",
    "    }]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Inference\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "@torch.inference_mode()\n",
    "def run_inference(messages, max_new_tokens):\n",
    "    \"\"\"Run model inference. max_new_tokens is passed explicitly per baseline.\"\"\"\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_dict=True,\n",
    "        return_tensors='pt',\n",
    "    ).to(model.device)\n",
    "    out_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "    new_ids = [o[len(i):] for i, o in zip(inputs.input_ids, out_ids)]\n",
    "    return processor.batch_decode(\n",
    "        new_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0].strip()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Parsing helpers\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def extract_action_line(text):\n",
    "    \"\"\"\n",
    "    Scan output bottom-to-top for the first valid action line.\n",
    "    Works for both direct and CoT outputs â€” CoT will have reasoning above,\n",
    "    the action line will be last.\n",
    "    \"\"\"\n",
    "    for line in reversed(text.splitlines()):\n",
    "        line = line.strip().lstrip('*-â€¢() ')\n",
    "        if re.match(r'^(CLICK|TYPE|SELECT|SCROLL|PRESS|STOP)\\b', line, re.I):\n",
    "            return line\n",
    "    return ''\n",
    "\n",
    "def parse_predicted_op(action_line):\n",
    "    m = re.match(r'^(CLICK|TYPE|SELECT|SCROLL|PRESS|STOP)\\b', action_line, re.I)\n",
    "    return m.group(1).upper() if m else 'UNKNOWN'\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ground truth helpers\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_gt_op(row):\n",
    "    for key in ['operation', 'action']:\n",
    "        op = row.get(key, {})\n",
    "        if isinstance(op, str):\n",
    "            try:\n",
    "                op = json.loads(op)\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                return op.upper().strip()\n",
    "        if isinstance(op, dict):\n",
    "            return (op.get('op') or op.get('original_op') or '').upper().strip()\n",
    "    return ''\n",
    "\n",
    "def get_gt_element(row):\n",
    "    try:\n",
    "        ti = int(row.get('target_action_index', -1))\n",
    "        cands = row.get('pos_candidates', [])\n",
    "        if cands and 0 <= ti < len(cands):\n",
    "            elem = cands[ti]\n",
    "            if isinstance(elem, dict):\n",
    "                return str(elem.get('backend_node_id', ''))\n",
    "    except (ValueError, TypeError, IndexError):\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def extract_gt_element_label(reprs):\n",
    "    m = re.match(r'\\[.*?\\]\\s*(.*?)\\s*->', reprs or '')\n",
    "    return m.group(1).strip().lower() if m else None\n",
    "\n",
    "def extract_pred_element_label(action_line):\n",
    "    m = re.match(r'^(?:CLICK|TYPE|SELECT|SCROLL|PRESS|STOP)\\s+(.*)', action_line or '', re.I)\n",
    "    return m.group(1).strip().lower() if m else None\n",
    "\n",
    "def op_match(pred_line, row):\n",
    "    return parse_predicted_op(pred_line) == get_gt_op(row)\n",
    "\n",
    "print('All helpers defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-09",
   "metadata": {},
   "source": [
    "## Cell 9 â€” ğŸ” Dry-run sanity check (3 samples, both baselines)\n",
    "**Run this before the full evaluation loop.**\n",
    "It prints raw output, extracted action line, parsed op, GT op, and match result\n",
    "for both baselines side by side so you can catch any parsing issues before a long run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "DRY RUN â€” axtree_multimodal  (max_new_tokens=32)\n",
      "=================================================================\n",
      "\n",
      "--- Sample 0 ---\n",
      "  Task          : What are the romantic reggae musics from BCD Studio that can be used in tik tok \n",
      "  Input tokens  : 432\n",
      "  Output tokens : ~23  |  Time: 5.8s\n",
      "  GT op         : CLICK\n",
      "  Raw output    :\n",
      "    STOP BCD Studio does not appear in the provided AXTree, and there is no visible content related to \"romantic reggae musics\" or \"And\n",
      "  Action line   : [STOP BCD Studio does not appear in the provided AXTree, and there is no visible content related to \"romantic reggae musics\" or \"And]\n",
      "  Pred op       : STOP\n",
      "  Match         : âŒ\n",
      "\n",
      "--- Sample 500 ---\n",
      "  Task          : Calculate the estimated car loan payment amount for an average credit-rated pers\n",
      "  Input tokens  : 486\n",
      "  Output tokens : ~11  |  Time: 4.7s\n",
      "  GT op         : TYPE\n",
      "  Raw output    :\n",
      "    TYPE car_value_input 15000\n",
      "    TYPE down_payment_input 2000\n",
      "    TYPE loan_tenure_input 48\n",
      "    SELECT zip\n",
      "  Action line   : [SELECT zip]\n",
      "  Pred op       : SELECT\n",
      "  Match         : âŒ\n",
      "\n",
      "--- Sample 1000 ---\n",
      "  Task          : Shop for 2020 made dry red wine made in Italy priced between 15-20 dollars and a\n",
      "  Input tokens  : 564\n",
      "  Output tokens : ~3  |  Time: 7.2s\n",
      "  GT op         : CLICK\n",
      "  Raw output    :\n",
      "    SELECT State/Province/Region AZ\n",
      "  Action line   : [SELECT State/Province/Region AZ]\n",
      "  Pred op       : SELECT\n",
      "  Match         : âŒ\n",
      "\n",
      "âš ï¸  Some mismatches â€” expected, check action lines are being extracted correctly.\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "DRY_RUN_SPLIT = 'test_website'\n",
    "DRY_RUN_INDICES = [0, 500, 1000]\n",
    "\n",
    "def dry_run(baseline_name, message_builder, max_new_tokens, split=DRY_RUN_SPLIT, indices=DRY_RUN_INDICES):\n",
    "    ds = datasets_dict[split]\n",
    "    print('=' * 65)\n",
    "    print(f'DRY RUN â€” {baseline_name}  (max_new_tokens={max_new_tokens})')\n",
    "    print('=' * 65)\n",
    "    all_ok = True\n",
    "    for i in indices:\n",
    "        row = ds[i]\n",
    "        messages = message_builder(row)\n",
    "\n",
    "        inputs = processor.apply_chat_template(\n",
    "            messages, tokenize=True, add_generation_prompt=True,\n",
    "            return_dict=True, return_tensors='pt'\n",
    "        ).to(model.device)\n",
    "        n_input_tokens = inputs.input_ids.shape[1]\n",
    "\n",
    "        start = time.time()\n",
    "        raw = run_inference(messages, max_new_tokens=max_new_tokens)\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        action_line = extract_action_line(raw)\n",
    "        pred_op     = parse_predicted_op(action_line)\n",
    "        gt_op       = get_gt_op(row)\n",
    "        match       = pred_op == gt_op\n",
    "        if not match:\n",
    "            all_ok = False\n",
    "\n",
    "        print(f'\\n--- Sample {i} ---')\n",
    "        print(f'  Task          : {row[\"confirmed_task\"][:80]}')\n",
    "        print(f'  Input tokens  : {n_input_tokens}')\n",
    "        print(f'  Output tokens : ~{len(raw.split())}  |  Time: {elapsed:.1f}s')\n",
    "        print(f'  GT op         : {gt_op}')\n",
    "        print(f'  Raw output    :')\n",
    "        raw_lines = raw.splitlines()\n",
    "        display_lines = raw_lines if len(raw_lines) <= 5 else ['...'] + raw_lines[-5:]\n",
    "        for l in display_lines:\n",
    "            print(f'    {l}')\n",
    "        print(f'  Action line   : [{action_line}]')\n",
    "        print(f'  Pred op       : {pred_op}')\n",
    "        print(f'  Match         : {\"âœ…\" if match else \"âŒ\"}')\n",
    "\n",
    "    print('\\n' + ('âœ… All samples matched GT op.' if all_ok else 'âš ï¸  Some mismatches â€” expected, check action lines are being extracted correctly.'))\n",
    "    print('=' * 65)\n",
    "\n",
    "# Baseline A â€” direct\n",
    "dry_run('axtree_multimodal', build_messages_axtree, max_new_tokens=CFG['max_new_tokens_direct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "DRY RUN â€” axtree_multimodal_cot  (max_new_tokens=512)\n",
      "=================================================================\n",
      "\n",
      "--- Sample 0 ---\n",
      "  Task          : What are the romantic reggae musics from BCD Studio that can be used in tik tok \n",
      "  Input tokens  : 448\n",
      "  Output tokens : ~64  |  Time: 9.4s\n",
      "  GT op         : CLICK\n",
      "  Raw output    :\n",
      "    STOP BCD Studio does not appear to be listed in the provided AXTree, and there is no visible content related to \"romantic reggae musics\" or \"Andorra\" on this page. The page shows a music library interface, but no specific search or filter for BCD Studio or romantic reggae is available. Therefore, it is not possible to determine the requested information from the current page.\n",
      "  Action line   : [STOP BCD Studio does not appear to be listed in the provided AXTree, and there is no visible content related to \"romantic reggae musics\" or \"Andorra\" on this page. The page shows a music library interface, but no specific search or filter for BCD Studio or romantic reggae is available. Therefore, it is not possible to determine the requested information from the current page.]\n",
      "  Pred op       : STOP\n",
      "  Match         : âŒ\n",
      "\n",
      "--- Sample 500 ---\n",
      "  Task          : Calculate the estimated car loan payment amount for an average credit-rated pers\n",
      "  Input tokens  : 502\n",
      "  Output tokens : ~206  |  Time: 22.5s\n",
      "  GT op         : TYPE\n",
      "  Raw output    :\n",
      "    ...\n",
      "    \n",
      "    Final action: Enter 15000 into the \"Car price\" input field.\n",
      "    \n",
      "    CLICK Car price\n",
      "    TYPE Car price 15000\n",
      "  Action line   : [TYPE Car price 15000]\n",
      "  Pred op       : TYPE\n",
      "  Match         : âœ…\n",
      "\n",
      "--- Sample 1000 ---\n",
      "  Task          : Shop for 2020 made dry red wine made in Italy priced between 15-20 dollars and a\n",
      "  Input tokens  : 580\n",
      "  Output tokens : ~96  |  Time: 16.4s\n",
      "  GT op         : CLICK\n",
      "  Raw output    :\n",
      "    ...\n",
      "    From the AXTree, I can see the current page is showing red wine products, but I need to filter by year (2020), type (dry red wine), country (Italy), and price range ($15-$20). The left sidebar has filters for \"Year,\" \"Type,\" \"Country,\" and \"Price,\" which are necessary to narrow down the search.\n",
      "    \n",
      "    The first step is to filter by year. I need to click on the \"Year\" filter to select 2020.\n",
      "    \n",
      "    CLICK Year\n",
      "  Action line   : [CLICK Year]\n",
      "  Pred op       : CLICK\n",
      "  Match         : âœ…\n",
      "\n",
      "âš ï¸  Some mismatches â€” expected, check action lines are being extracted correctly.\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Baseline B â€” CoT  â† most important to verify\n",
    "dry_run('axtree_multimodal_cot', build_messages_axtree_cot, max_new_tokens=CFG['max_new_tokens_cot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-10",
   "metadata": {},
   "source": [
    "## Cell 10 â€” Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate() ready.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(baseline_name, message_builder, max_new_tokens, datasets_dict):\n",
    "    \"\"\"\n",
    "    Run inference across all splits and save per-split JSONL prediction files.\n",
    "    Returns dict of split -> list of result dicts.\n",
    "    \"\"\"\n",
    "    all_results = {}\n",
    "    for split, ds in datasets_dict.items():\n",
    "        results, n_correct = [], 0\n",
    "        pbar = tqdm(range(len(ds)), desc=f'{baseline_name} | {split}')\n",
    "        for i in pbar:\n",
    "            row = ds[i]\n",
    "            try:\n",
    "                raw = run_inference(message_builder(row), max_new_tokens=max_new_tokens)\n",
    "            except Exception as e:\n",
    "                results.append({'idx': i, 'error': str(e), 'correct': False,\n",
    "                                'predicted_op': 'UNKNOWN', 'predicted_action': ''})\n",
    "                continue\n",
    "\n",
    "            action_line = extract_action_line(raw)\n",
    "            correct     = op_match(action_line, row)\n",
    "            n_correct  += int(correct)\n",
    "            results.append({\n",
    "                'idx'                : i,\n",
    "                'annotation_id'      : row.get('annotation_id', ''),\n",
    "                'action_uid'         : row.get('action_uid', ''),\n",
    "                'confirmed_task'     : row['confirmed_task'],\n",
    "                'gt_op'              : get_gt_op(row),\n",
    "                'gt_element'         : get_gt_element(row),\n",
    "                'target_action_reprs': row.get('target_action_reprs', ''),\n",
    "                'raw_output'         : raw,\n",
    "                'predicted_action'   : action_line,\n",
    "                'predicted_op'       : parse_predicted_op(action_line),\n",
    "                'correct'            : correct,\n",
    "            })\n",
    "            pbar.set_postfix(acc=f'{n_correct/len(results):.3f}')\n",
    "\n",
    "        acc = n_correct / len(results) if results else 0.0\n",
    "        print(f'  [{split}] op-accuracy: {acc:.3f}  ({n_correct}/{len(results)})')\n",
    "        all_results[split] = results\n",
    "\n",
    "        # Save predictions\n",
    "        out = Path(CFG['output_dir']) / f'{baseline_name}_{split}.json'\n",
    "        with open(out, 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "        print(f'  Saved -> {out}')\n",
    "\n",
    "    return all_results\n",
    "\n",
    "print('evaluate() ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e088a2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4941c965a546188bfe5d6c83c0b585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "smoke_test_cot | test_website:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [test_website] op-accuracy: 0.667  (2/3)\n",
      "  Saved -> results/smoke_test_cot_test_website.json\n",
      "\n",
      "â”€â”€ Smoke-test results â”€â”€\n",
      "\n",
      "  idx=0  GT=CLICK  PRED=STOP  match=False\n",
      "  action_line : [STOP BCD Studio does not appear to be listed in the provided AXTree, and there is no visible content related to \"romantic reggae musics\" or \"Andorra\" on this page. The page shows a music library interface, but no specific search or filter for BCD Studio or romantic reggae is available. Therefore, it is not possible to determine the requested information from the current page.]\n",
      "  raw_output (last 3 lines):\n",
      "    STOP BCD Studio does not appear to be listed in the provided AXTree, and there is no visible content related to \"romantic reggae musics\" or \"Andorra\" on this page. The page shows a music library interface, but no specific search or filter for BCD Studio or romantic reggae is available. Therefore, it is not possible to determine the requested information from the current page.\n",
      "\n",
      "  idx=1  GT=TYPE  PRED=TYPE  match=True\n",
      "  action_line : [TYPE Car price 15000]\n",
      "  raw_output (last 3 lines):\n",
      "    \n",
      "    CLICK Car price\n",
      "    TYPE Car price 15000\n",
      "\n",
      "  idx=2  GT=CLICK  PRED=CLICK  match=True\n",
      "  action_line : [CLICK Year]\n",
      "  raw_output (last 3 lines):\n",
      "    The first step is to filter by year. I need to click on the \"Year\" filter to select 2020.\n",
      "    \n",
      "    CLICK Year\n",
      "\n",
      "â”€â”€ File check â”€â”€\n",
      "  Records saved : 3  (expected 3)\n",
      "  Keys in record: ['idx', 'annotation_id', 'action_uid', 'confirmed_task', 'gt_op', 'gt_element', 'target_action_reprs', 'raw_output', 'predicted_action', 'predicted_op', 'correct']\n",
      "  All have raw_output: True\n",
      "  All have predicted_op: True\n",
      "âœ… evaluate() smoke-test done.\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ Smoke-test evaluate() on 3 samples before full run â”€â”€\n",
    "test_ds_small = datasets_dict['test_website'].select([0, 500, 1000])\n",
    "\n",
    "results_smoke = evaluate(\n",
    "    'smoke_test_cot',\n",
    "    build_messages_axtree_cot,\n",
    "    max_new_tokens=CFG['max_new_tokens_cot'],\n",
    "    datasets_dict={'test_website': test_ds_small},\n",
    ")\n",
    "\n",
    "# Inspect results\n",
    "print('\\nâ”€â”€ Smoke-test results â”€â”€')\n",
    "for r in results_smoke['test_website']:\n",
    "    print(f\"\\n  idx={r['idx']}  GT={r['gt_op']}  PRED={r['predicted_op']}  match={r['correct']}\")\n",
    "    print(f\"  action_line : [{r['predicted_action']}]\")\n",
    "    print(f\"  raw_output (last 3 lines):\")\n",
    "    for l in r['raw_output'].splitlines()[-3:]:\n",
    "        print(f\"    {l}\")\n",
    "\n",
    "# Verify the saved file\n",
    "smoke_path = Path(CFG['output_dir']) / 'smoke_test_cot_test_website.json'\n",
    "with open(smoke_path) as f:\n",
    "    saved = json.load(f)\n",
    "print(f'\\nâ”€â”€ File check â”€â”€')\n",
    "print(f'  Records saved : {len(saved)}  (expected 3)')\n",
    "print(f'  Keys in record: {list(saved[0].keys())}')\n",
    "print(f'  All have raw_output: {all(\"raw_output\" in r for r in saved)}')\n",
    "print(f'  All have predicted_op: {all(\"predicted_op\" in r for r in saved)}')\n",
    "print('âœ… evaluate() smoke-test done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-11",
   "metadata": {},
   "source": [
    "## Cell 11 â€” Run Baseline A: axtree_multimodal\n",
    "Direct prediction. Runs on all 3 splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e099936cc840d18914710a4a372cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "axtree_multimodal | test_website:   0%|          | 0/1019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [test_website] op-accuracy: 0.341  (347/1019)\n",
      "  Saved -> results/axtree_multimodal_test_website.json\n"
     ]
    }
   ],
   "source": [
    "results_axtree = evaluate(\n",
    "    'axtree_multimodal',\n",
    "    build_messages_axtree,\n",
    "    max_new_tokens=CFG['max_new_tokens_direct'],\n",
    "    datasets_dict={'test_website': datasets_dict['test_website']},  # only test_website\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-12",
   "metadata": {},
   "source": [
    "## Cell 12 â€” Run Baseline B: axtree_multimodal_cot\n",
    "Chain-of-Thought. Uses `max_new_tokens_cot=512` so the model has room to reason\n",
    "before writing the final action line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dcd7d1181e4e2f97f60cc579690c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "axtree_multimodal_cot | test_website:   0%|          | 0/1019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [test_website] op-accuracy: 0.329  (335/1019)\n",
      "  Saved -> results/axtree_multimodal_cot_test_website.json\n"
     ]
    }
   ],
   "source": [
    "results_axtree_cot = evaluate(\n",
    "    'axtree_multimodal_cot',\n",
    "    build_messages_axtree_cot,\n",
    "    max_new_tokens=CFG['max_new_tokens_cot'],\n",
    "    datasets_dict={'test_website': datasets_dict['test_website']},  # only test_website\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-13",
   "metadata": {},
   "source": [
    "## Cell 13 â€” Compute & display metrics for both baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_metrics() ready.\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(results_list, baseline_name, output_dir):\n",
    "    \"\"\"\n",
    "    Compute all metrics aligned with vlm_inference_script.py checklist:\n",
    "      - Element Accuracy (label-based, since backend_node_id not in preds)\n",
    "      - Action Accuracy (op type)\n",
    "      - Exact Match (element label + action op)\n",
    "      - Parse Failure Rate\n",
    "      - Per-action Precision/Recall/F1\n",
    "      - Task Success Rate (all steps of same annotation_id correct)\n",
    "    \"\"\"\n",
    "    n = len(results_list)\n",
    "    if n == 0:\n",
    "        print('No results to compute metrics from.')\n",
    "        return {}\n",
    "\n",
    "    # Parse failures â€” no valid action extracted\n",
    "    n_parse_fail = sum(1 for r in results_list\n",
    "                       if r.get('predicted_op') == 'UNKNOWN' or r.get('predicted_action') == '')\n",
    "\n",
    "    # Action accuracy\n",
    "    action_acc = sum(1 for r in results_list if r.get('correct')) / n\n",
    "\n",
    "    # Element & exact match (label-based)\n",
    "    elem_correct = 0\n",
    "    exact_correct = 0\n",
    "    for r in results_list:\n",
    "        gt_label   = extract_gt_element_label(r.get('target_action_reprs', ''))\n",
    "        pred_label = extract_pred_element_label(r.get('predicted_action', ''))\n",
    "        gt_op      = r.get('gt_op', '')\n",
    "        pred_op    = r.get('predicted_op', '')\n",
    "        if gt_label and pred_label and gt_label in pred_label:\n",
    "            elem_correct += 1\n",
    "            if pred_op == gt_op:\n",
    "                exact_correct += 1\n",
    "    element_acc = elem_correct / n\n",
    "    exact_match = exact_correct / n\n",
    "\n",
    "    # Per-action P/R/F1\n",
    "    gt_ops   = [r.get('gt_op', 'UNKNOWN')      for r in results_list]\n",
    "    pred_ops = [r.get('predicted_op', 'UNKNOWN') for r in results_list]\n",
    "    all_ops  = sorted(set(gt_ops))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(set(gt_ops + pred_ops)))\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        le.transform(gt_ops), le.transform(pred_ops),\n",
    "        labels=le.transform(all_ops), zero_division=0\n",
    "    )\n",
    "\n",
    "    # Task success rate\n",
    "    task_groups = defaultdict(list)\n",
    "    for r in results_list:\n",
    "        task_groups[r.get('annotation_id', r['idx'])].append(r.get('correct', False))\n",
    "    task_success = (sum(all(v) for v in task_groups.values()) / len(task_groups)\n",
    "                    if task_groups else 0.0)\n",
    "\n",
    "    # Print\n",
    "    sep = '=' * 60\n",
    "    print(sep)\n",
    "    print(f'{\"Baseline\":<22}: {baseline_name}')\n",
    "    print(f'{\"Num samples\":<22}: {n}')\n",
    "    print(f'{\"Parse failure\":<22}: {n_parse_fail/n:.3f}  ({n_parse_fail}/{n})')\n",
    "    print(f'{\"Element Acc\":<22}: {element_acc:.3f}')\n",
    "    print(f'{\"Action Acc\":<22}: {action_acc:.3f}')\n",
    "    print(f'{\"Exact Match\":<22}: {exact_match:.3f}')\n",
    "    print(f'{\"Task Success Rate\":<22}: {task_success:.3f}')\n",
    "    print(f'\\nPer-action breakdown:')\n",
    "    for op, p, r, f, s in zip(all_ops, precision, recall, f1, support):\n",
    "        print(f'  {op:<12} P={p:.3f}  R={r:.3f}  F1={f:.3f}  support={s}')\n",
    "    print(sep)\n",
    "\n",
    "    metrics = {\n",
    "        'baseline'          : baseline_name,\n",
    "        'n'                 : n,\n",
    "        'parse_failure_rate': n_parse_fail / n,\n",
    "        'element_acc'       : element_acc,\n",
    "        'action_acc'        : action_acc,\n",
    "        'exact_match'       : exact_match,\n",
    "        'task_success_rate' : task_success,\n",
    "        'per_action'        : {\n",
    "            op: {'precision': float(p), 'recall': float(r), 'f1': float(f), 'support': int(s)}\n",
    "            for op, p, r, f, s in zip(all_ops, precision, recall, f1, support)\n",
    "        },\n",
    "    }\n",
    "    out = Path(output_dir) / f'{baseline_name}_metrics.json'\n",
    "    with open(out, 'w') as fout:\n",
    "        json.dump(metrics, fout, indent=2)\n",
    "    print(f'Metrics saved to: {out}')\n",
    "    return metrics\n",
    "\n",
    "print('compute_metrics() ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Baseline A â€” axtree_multimodal\n",
      "============================================================\n",
      "Baseline              : axtree_multimodal_test_website\n",
      "Num samples           : 1019\n",
      "Parse failure         : 0.000  (0/1019)\n",
      "Element Acc           : 0.088\n",
      "Action Acc            : 0.341\n",
      "Exact Match           : 0.044\n",
      "Task Success Rate     : 0.042\n",
      "\n",
      "Per-action breakdown:\n",
      "  CLICK        P=0.821  R=0.365  F1=0.505  support=827\n",
      "  SELECT       P=0.143  R=0.083  F1=0.105  support=72\n",
      "  TYPE         P=0.239  R=0.325  F1=0.276  support=120\n",
      "============================================================\n",
      "Metrics saved to: results/axtree_multimodal_test_website_metrics.json\n",
      "\n",
      ">>> Baseline B â€” axtree_multimodal_cot\n",
      "============================================================\n",
      "Baseline              : axtree_multimodal_cot_test_website\n",
      "Num samples           : 1019\n",
      "Parse failure         : 0.024  (24/1019)\n",
      "Element Acc           : 0.076\n",
      "Action Acc            : 0.329\n",
      "Exact Match           : 0.043\n",
      "Task Success Rate     : 0.014\n",
      "\n",
      "Per-action breakdown:\n",
      "  CLICK        P=0.851  R=0.386  F1=0.531  support=827\n",
      "  SELECT       P=0.200  R=0.042  F1=0.069  support=72\n",
      "  TYPE         P=0.295  R=0.108  F1=0.159  support=120\n",
      "============================================================\n",
      "Metrics saved to: results/axtree_multimodal_cot_test_website_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ Compute metrics for the split you care about most â”€â”€\n",
    "# Change the key to 'test_task' or 'test_domain' as needed.\n",
    "\n",
    "TARGET_SPLIT = 'test_website'\n",
    "\n",
    "print('\\n>>> Baseline A â€” axtree_multimodal')\n",
    "metrics_a = compute_metrics(\n",
    "    results_axtree[TARGET_SPLIT],\n",
    "    baseline_name=f'axtree_multimodal_{TARGET_SPLIT}',\n",
    "    output_dir=CFG['output_dir'],\n",
    ")\n",
    "\n",
    "print('\\n>>> Baseline B â€” axtree_multimodal_cot')\n",
    "metrics_b = compute_metrics(\n",
    "    results_axtree_cot[TARGET_SPLIT],\n",
    "    baseline_name=f'axtree_multimodal_cot_{TARGET_SPLIT}',\n",
    "    output_dir=CFG['output_dir'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-14",
   "metadata": {},
   "source": [
    "## Cell 14 â€” Side-by-side comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                     axtree_multimodal_test_website      axtree_multimodal_cot_test_website  Delta\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Parse Failure Rate         0.000                               0.024                               â–²0.024\n",
      "Element Accuracy           0.088                               0.076                               â–¼0.013\n",
      "Action Accuracy            0.341                               0.329                               â–¼0.012\n",
      "Exact Match                0.044                               0.043                               â–¼0.001\n",
      "Task Success Rate          0.042                               0.014                               â–¼0.028\n"
     ]
    }
   ],
   "source": [
    "def comparison_table(metrics_a, metrics_b):\n",
    "    keys = ['parse_failure_rate', 'element_acc', 'action_acc', 'exact_match', 'task_success_rate']\n",
    "    labels = ['Parse Failure Rate', 'Element Accuracy', 'Action Accuracy', 'Exact Match', 'Task Success Rate']\n",
    "    name_a = metrics_a.get('baseline', 'Baseline A')\n",
    "    name_b = metrics_b.get('baseline', 'Baseline B')\n",
    "    col_w  = max(len(name_a), len(name_b), 30)\n",
    "    header = f'{\"Metric\":<25}  {name_a:<{col_w}}  {name_b:<{col_w}}  Delta'\n",
    "    print(header)\n",
    "    print('-' * len(header))\n",
    "    for k, label in zip(keys, labels):\n",
    "        va = metrics_a.get(k, 0.0)\n",
    "        vb = metrics_b.get(k, 0.0)\n",
    "        delta = vb - va\n",
    "        arrow = 'â–²' if delta > 0 else ('â–¼' if delta < 0 else ' ')\n",
    "        print(f'{label:<25}  {va:<{col_w}.3f}  {vb:<{col_w}.3f}  {arrow}{abs(delta):.3f}')\n",
    "\n",
    "comparison_table(metrics_a, metrics_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-15",
   "metadata": {},
   "source": [
    "## Cell 15 â€” (Optional) Inspect failures\n",
    "Print the first N samples where the model was wrong so you can review raw outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_failures(results_list, baseline_name, n=5):\n",
    "    failures = [r for r in results_list if not r.get('correct')]\n",
    "    print(f'{baseline_name}: {len(failures)} failures out of {len(results_list)}')\n",
    "    for r in failures[:n]:\n",
    "        print(f'\\n  idx={r[\"idx\"]}  GT={r[\"gt_op\"]}  PRED={r[\"predicted_op\"]}')\n",
    "        print(f'  Task : {r[\"confirmed_task\"][:80]}')\n",
    "        print(f'  Pred action line : [{r[\"predicted_action\"]}]')\n",
    "        # For CoT: show last 5 lines of raw output\n",
    "        raw_lines = r.get('raw_output', '').splitlines()\n",
    "        tail = raw_lines[-5:] if len(raw_lines) > 5 else raw_lines\n",
    "        print(f'  Raw output (last 5 lines):')\n",
    "        for l in tail:\n",
    "            print(f'    {l}')\n",
    "\n",
    "inspect_failures(results_axtree[TARGET_SPLIT],     'axtree_multimodal')\n",
    "inspect_failures(results_axtree_cot[TARGET_SPLIT], 'axtree_multimodal_cot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
